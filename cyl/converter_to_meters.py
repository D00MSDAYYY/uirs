import numpy as np
import os
import re
import requests


def download_img(url=None, filename="ldem_64.img", save_path=None):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª ldem_64.img —Å —Å–∞–π—Ç–∞ PDS Geosciences

    Parameters:
    -----------
    url : str, optional
        URL —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è. –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π URL
    filename : str, optional
        –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ldem_64.img)
    save_path : str, optional
        –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞. –ï—Å–ª–∏ None, —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏

    Returns:
    --------
    str : –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π URL –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω –¥—Ä—É–≥–æ–π
    if url is None:
        url = "https://pds-geosciences.wustl.edu/lro/lro-l-lola-3-rdr-v1/lrolol_1xxx/DATA/LOLA_GDR/cylindrical/img/ldem_64.img"

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    if save_path is None:
        save_path = os.path.join(os.getcwd(), filename)
    else:
        save_path = os.path.join(save_path, filename)

    try:
        print(f"–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞ —Å URL: {url}")
        print(f"–§–∞–π–ª –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫: {save_path}")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º GET –∑–∞–ø—Ä–æ—Å —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π –¥–∞–Ω–Ω—ã—Ö
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏ HTTP

        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = int(response.headers.get("content-length", 0))
        print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size / (1024*1024):.2f} MB")

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        with open(save_path, "wb") as file:
            downloaded = 0
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    file.write(chunk)
                    downloaded += len(chunk)

                    # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                    if file_size > 0:
                        percent = (downloaded / file_size) * 100
                        print(
                            f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {percent:.1f}% ({downloaded/(1024*1024):.1f}/{file_size/(1024*1024):.1f} MB)",
                            end="\r",
                        )

        print(f"\n–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω: {save_path}")
        return save_path

    except requests.exceptions.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return None
    except Exception as e:
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        return None


def parse_pds_label(label_file):
    """–ü–∞—Ä—Å–∏—Ç PDS .lbl —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö"""

    params = {}

    try:
        with open(label_file, "r", encoding="utf-8") as f:
            content = f.read()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        patterns = {
            "lines": r"LINES\s*=\s*(\d+)",
            "line_samples": r"LINE_SAMPLES\s*=\s*(\d+)",
            "scaling_factor": r"SCALING_FACTOR\s*=\s*([\d\.]+)",
            "offset": r"OFFSET\s*=\s*([\d\.]+)",
            "sample_bits": r"SAMPLE_BITS\s*=\s*(\d+)",
            "file_records": r"FILE_RECORDS\s*=\s*(\d+)",
            "record_bytes": r"RECORD_BYTES\s*=\s*(\d+)",
            "map_resolution": r"MAP_RESOLUTION\s*=\s*(\d+)",
            "map_scale": r"MAP_SCALE\s*=\s*([\d\.]+)",
        }

        for key, pattern in patterns.items():
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                try:
                    if key in ["scaling_factor", "offset", "map_scale"]:
                        params[key] = float(match.group(1))
                    else:
                        params[key] = int(match.group(1))
                except ValueError:
                    # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                    params[key] = match.group(1)
                    print("err key", key)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        string_patterns = {"file_name": r"FILE_NAME\s*=\s*\"([^\"]+)\""}

        for key, pattern in string_patterns.items():
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                params[key] = match.group(1)

        print("‚úì –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ PDS —Ñ–∞–π–ª–∞:")
        for key, value in params.items():
            print(f"  {key}: {value}")

        return params

    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDS —Ñ–∞–π–ª–∞: {e}")
        return None


def convert_ldem_to_meters(label_file):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç LDEM –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ PDS .lbl —Ñ–∞–π–ª–∞"""
    params = parse_pds_label(label_file)

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    SCALING_FACTOR = params.get("scaling_factor")
    OFFSET = params.get("offset")
    NROWS = params.get("lines")
    NCOLS = params.get("line_samples")
    SAMPLE_BITS = params.get("sample_bits")
    input_file = params.get("file_name")

    output_file = os.path.splitext(label_file)[0] + "_meters.dat"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not os.path.exists(input_file):
        print(f"‚úó –û—à–∏–±–∫–∞: —Ñ–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return

    print(f"\nüìä –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ {input_file}...")
    print(f"   –†–∞–∑–º–µ—Ä: {NCOLS} √ó {NROWS} –ø–∏–∫—Å–µ–ª–µ–π")
    print(f"   –§–æ—Ä–º—É–ª–∞: –≤—ã—Å–æ—Ç–∞ = (–¥–∞–Ω–Ω—ã–µ √ó {SCALING_FACTOR})")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ sample_bits
    if SAMPLE_BITS == 16:
        dtype = ">i2"  # big-endian int16
    else:
        dtype = ">i4"  # big-endian int32 (–Ω–∞ —Å–ª—É—á–∞–π –¥—Ä—É–≥–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤)

    # –ß–∏—Ç–∞–µ–º –±–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("üì• –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    try:
        with open(input_file, "rb") as f:
            data = np.fromfile(f, dtype=dtype)
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
    expected_size = NCOLS * NROWS
    if len(data) != expected_size:
        print(
            f"‚ö† –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_size} –∑–Ω–∞—á–µ–Ω–∏–π, –ø–æ–ª—É—á–µ–Ω–æ {len(data)}"
        )
        quit()

    # –ò–∑–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º—É –º–∞—Å—Å–∏–≤–∞
    data = data.reshape(NROWS, NCOLS)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –º–µ—Ç—Ä—ã - –í–ù–ò–ú–ê–ù–ò–ï: —Ç–æ–ª—å–∫–æ —É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞ scaling_factor!
    print("üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –º–µ—Ç—Ä—ã...")
    elevation_meters = data.astype(np.float32) * SCALING_FACTOR

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
    elevation_meters.astype(np.float32).tofile(output_file)

    # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    params_file = os.path.splitext(label_file)[0] + "_params.npy"
    np.save(params_file, params)
    print(f"‚úì –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {params_file}")

    return params


if __name__ == "__main__":
    download_img()
    # –£–∫–∞–∑—ã–≤–∞–µ–º –∏–º—è .lbl —Ñ–∞–π–ª–∞
    LBL_FILE = "ldem_64.lbl"
    params = convert_ldem_to_meters(LBL_FILE)
